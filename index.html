<!DOCTYPE html>
<html>
<head>
    <title>Juntang Zhuang</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
          body {
            font-family: 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;
          }
          #header {
            background-color: #f4f4f4;
            /*background-color: #FFFFFF;*/
            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
          }
          #footer {
            background-color: #FFFFFF;
            padding:60px;
          }
          #portrait {
            border: 3px solid white;
          }
          #header-text {
            margin-top: 60px;
            margin-left: 220px;
          }
          #header-text-name {
            font-size: 40px;
          }
          #header-text-email {
            font-size: 20px;
            font-style: italic;
          }
          .header-text-desc {
            font-size: 20px;
          }
          .vspace-top {
            margin-top: 30px;
          }
          .vspace-top-news {
              margin-top: 15px;
          }
          .paper-image {
            width: 150px;
          }
          .news-date {
              font-weight: bold;
          }
          .paper-title {
            font-weight: bold;
          }
          .paper-authors {
            font-style: italic;
          }
    </style>
</head>

<body>
    <center>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <!---
                <div class="col-sm-3 offset-sm-1">
                    <img src='imgs/portrait.jpeg' class='img-fluid' id='portrait'>
                </div>
                -->
                
                <div class="col">
                  <div id='header-text-name'>
                      Juntang Zhuang
                  </div>
                  <div id='header-text-email'>
                    zhuangjt12@gmail.com
                  </div>
                  <div>
                    <a href="https://github.com/juntang-zhuang">[GitHub]</a>
                    <a href="https://scholar.google.com/citations?user=78_Vob4AAAAJ&hl=en">[Google Scholar]</a>
                    <a href="https://twitter.com/JuntangZhuang">[Twitter]</a>
                  </div>
                </div>
            </div>
        </div>
    </div>
    </center>



    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>
                <p>
                    I am a Research Sceintist at <a href="https://openai.com/">OpenAI</a>. I'm recognized as a primary contributor to DALL-E 3, a core contributor to
                    Embedding V3, and a core contributor to GPT4-Turbo long-context capability. My research interest lies in machine learning, optimization, large language models, numerical methods and theories.
                </p>


                <div class='vspace-top'>
                    <h1>Projects</h1>
                </div>
                <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://openai.com/blog/new-models-and-developer-products-announced-at-devday">GPT4-Turbo</a>: core contributor
                </div>
                <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://openai.com/dall-e-3">DALL &middot E3</a>: primary contributor
                </div>

                <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://platform.openai.com/docs/guides/embeddings/what-are-embeddings"> OpenAI Embedding </a>: core contributor</div>

                <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://arxiv.org/abs/2303.08774"> GPT-4 </a>: co-author
                <div class='vspace-top'>
                    <h1>Sample Packages</h1>
                </div>
                <div>
                            1. AdaBelief optimizer implemented in <a href="https://github.com/juntang-zhuang/Adabelief-Optimizer">[PyTorch]</a>,
                            <a href="https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdaBelief">[Tensorflow-Addons]</a>,
                            <a href="https://flax.readthedocs.io/en/latest/_autosummary/flax.optim.AdaBelief.html">[Google Flax]</a>,
                            <a href="https://optax.readthedocs.io/en/latest/api.html#optax.adabelief">[Deepmind Optax]</a>.
                </div>
                <div>
                            2. <a href="https://jzkay12.github.io/TorchDiffEqPack/">[TorchDiffEqPack]</a> for accurate and memory-efficient ODE solvers for deep learning.
                </div>

                <!--- List of news 
                <div class='vspace-top'>
                    <h1>News</h1>
                </div>
                
                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        June 2020
                    </div>
                    <div class="col">
                        I'll join Josh Tenenbaum's group as a Postdoc in August. If you're in Boston and wanna talk
                        Neural Representations, reach out!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        June 2020
                    </div>
                    <div class="col">
                        I just graduated Stanford with my <a href="docs/self_supervised_scene_rep_learning_vsitzmann.pdf">
                        thesis on Self-supervised Scene Representation Learning</a>. There's a few interesting thoughts in there -
                        especially check out the introduction and conclusion!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        March 2020
                    </div>
                    <div class="col">
                        Our CVPR tutorial on Neural Rendering is on youtube, free to watch for everyone!
                        Here's the <a href="https://www.youtube.com/watch?v=LCTYRqW-ne8">link to the morning session</a> -
                        at 2:20:00, I'm giving an overview over Novel View Synthesis.
                        Here's the <a href="https://www.youtube.com/watch?v=JlyGNvbGKB8">link to the afternoon session</a>.
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        March 2020
                    </div>
                    <div class="col">
                        Our state-of-the-art report on neural rendering was accepted to Eurographics 2020.
                        Drop by our tutorial!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        November 2019
                    </div>

                    <div class="col">
		    	Our paper "Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations" wins an honorable mention for "Outstanding New Directions" at NeurIPS 2019! Watch my talk <a href="https://slideslive.com/38921749/track-1-session-3">here</a>.
                    </div>
                </div>


                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        May 2019
                    </div>

                    <div class="col">
                        I will join Prof. Noah Snavely's group at the Google NYC office over the summer and continue working
                        on  deep learning for scene understanding and novel view synthesis.
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        March 2019
                    </div>

                    <div class="col">
                        Our paper "DeepVoxels: Learning Persistent 3D Feature Embeddings" was accepted to CVPR as an oral!
                        I will be in Los Angeles from June 16 to June 21 to present the paper.
                    </div>
                </div>
                --->

                <div class='vspace-top'>
                    <h1>Publications</h1>
                </div>

                <!--- List of publications --->
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img width="70%" src="imgs/dalle3.png">
                        </img>
                    </div>
                
                    <div class="col">
                        <div class='paper-title'>
                            <a href="https://cdn.openai.com/papers/dall-e-3.pdf">Improving Image Generation with Better Captions</a>
                        </div>
                    </div>
                </div>
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img width="70%" src="imgs/gpt4-logo.png">
                        </img>
                    </div>
                
                    <div class="col">
                        <div class='paper-title'>
                            <a href="https://cdn.openai.com/papers/gpt-4.pdf">GPT-4 Technical Report</a>
                        </div>
                    </div>
                </div>
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img width="120%" src="gsam/gsam.jpg">
                        </img>
                    </div>
                
                    <div class="col">
                        <div class='paper-title'>
                            Surrogate Gap Minimization improves Sharpness-Aware Training 
                        </div>
                        <div class='paper-desc'>
                            ICLR 2022
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Boqing Gong, Liangzhe Yuan, Yin Cui, Hartwig Adam, Nicha Dvornek, Sekhar Tatikonda, James S. Duncan, Ting Liu
                        </div>
                        <div>
                            <a href="https://sites.google.com/view/gsam-iclr22/home">[Project page]</a>
                            <a href="https://arxiv.org/pdf/2203.08065.pdf">[Paper]</a>
                            <a href="https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/gsam/gsam.py">[Code]</a>
                            <a href="gsam/gsam.txt">[Citation]</a>
                            <a href="https://github.com/google-research/big_vision/pull/8#pullrequestreview-1078557411">[Reproduced results (credit to Lucas Beyer)]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img width="120%"  src="acprop/img/rosenbrock_acprop.gif">
                        </img>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Momentum Centering and Asynchronous Update for Adaptive Gradient Methods
                        </div>
                        <div class='paper-desc'>
			    NeurIPS 2021
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>,  Yifan Ding,  Tommy Tang, Nicha Dvornek, Sekhar Tatikonda, James S. Duncan
                        </div>
                        <div>
                            <a href="./acprop/index.html">[Project page]</a>
		            <a href="https://arxiv.org/abs/2110.05454">[Paper]</a>
                            <a href="https://github.com/juntang-zhuang/ACProp-Optimizer">[Code]</a>
                            <a href="acprop/citation.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="torch_diffeq_pack/img/mali_front.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            MALI: A memory efficient and reverse accurate integrator for Neural ODEs
                        </div>
                        <div class='paper-desc'>
			    ICLR 2021
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Nicha Dvornek, Sekhar Tatikonda, James S. Duncan
                        </div>
                        <div>
                            <a href="./torch_diffeq_pack/index.html">[Project page]</a>
                            <a href="https://arxiv.org/abs/2102.04668">[Paper]</a>
                            <a href="https://github.com/juntang-zhuang/TorchDiffEqPack">[Code]</a>
                            <a href="https://jzkay12.github.io/TorchDiffEqPack">[Package]</a>
                            <a href="torch_diffeq_pack/citation.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="multiple_shooting_adjoint/img/nonlinear2.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Multiple-shooting adjoint method for whole-brain dynamic causal modeling
                        </div>
                        <div class='paper-desc'>
			    IPMI 2021 (Oral presentation)
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Nicha Dvornek, Sekhar Tatikonda,  Xenophon Papademetris, Pamela Ventola, James S. Duncan
                        </div>
                        <div>
                            <a href="./multiple_shooting_adjoint/index.html">[Project page]</a>
                            <a href="https://arxiv.org/abs/2102.11013">[Paper]</a>
                            <a href="https://github.com/juntang-zhuang/TorchDiffEqPack">[Code]</a>
                            <a href="https://jzkay12.github.io/TorchDiffEqPack">[Package]</a>
                            <a href="multiple_shooting_adjoint/citation.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="adabelief/img/Beale2.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients
                        </div>
                        <div class='paper-desc'>
			    NeurIPS 2020 (Spotlight, Top 5%)
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Tommy Tang, Yifan Ding, Sekhar Tatikonda, Nicha Dvornek, Xenophon Papademetris, James S. Duncan
                        </div>
                        <div>
                            <a href="./adabelief/index.html">[Project page]</a>
                            <a href="https://arxiv.org/abs/2010.07468">[Paper]</a>
                            <a href="https://github.com/juntang-zhuang/Adabelief-Optimizer">[Code]</a>
                            <a href="adabelief/citation.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="adaptive_ckpt_adjoint/img/grad_error.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Adaptive Checkpoint Adjoint Method for Gradient Estimation in Neural ODE
                        </div>
                        <div class='paper-desc'>
			                ICML 2020
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Xiaoxiao Li, , Nicha Dvornek, Sekhar Tatikonda, Xenophon Papademetris, James S. Duncan
                        </div>
                        <div>
                            <a href="./adaptive_ckpt_adjoint/index.html">[Project page]</a>
                            <a href="https://arxiv.org/abs/2006.02493">[Paper]</a>
                            <a href="https://icml.cc/media/Slides/icml/2020/virtual(no-parent)-16-13-00UTC-5900-adaptive_checkp.pdf"> [Slides]</a>
                            <a href="https://github.com/juntang-zhuang/torch_ACA">[Code]</a>
                            <a href="adaptive_ckpt_adjoint/citation.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/invnet.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Decision Explanation and Feature Importance for Invertible Networks
                        </div>
                        <div class='paper-desc'>
			                ICCV 2019, XAIC (Oral presentation)
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Nicha C. Dvornek, Xiaoxiao Li, Junlin Yang, James S. Duncan
                        </div>
                        <div>
                            <a href="https://arxiv.org/pdf/1910.00406.pdf">[Paper]</a>
                            <a href="https://docs.google.com/presentation/d/1tmsWDohlSGfI3Ay6xYoJvdnERzY9wo9OhKQ0AUtZL8U/edit?usp=sharing"> [Slides]</a>
                            <a href="https://github.com/juntang-zhuang/explain_invertible">[Code]</a>
                            <a href="other_citations/invnet.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/shelfnet.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            ShelfNet for fast semantic segmentation
                        </div>
                        <div class='paper-desc'>
			                ICCV 2019, CVRSUAD
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Junlin Yang, Lin Gu, Nicha C. Dvornek.
                        </div>
                        <div>
                            <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Zhuang_ShelfNet_for_Fast_Semantic_Segmentation_ICCVW_2019_paper.pdf">[Paper]</a>
                            <a href="https://github.com/juntang-zhuang/ShelfNet">[Code]</a>
                            <a href="other_citations/shelfnet.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/invnet_asd.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Invertible Network for Classification and Biomarker Selection for ASD
                        </div>
                        <div class='paper-desc'>
			                MICCAI 2019
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Nicha C. Dvornek, Xiaoxiao Li, Junlin Yang, James S. Duncan.
                        </div>
                        <div>
                            <a href="Invertible Network for Classification and Biomarker Selection for ASD">[Paper]</a>
                            <a href="https://github.com/juntang-zhuang/explain_invertible">[Code]</a>
                            <a href="other_citations/invnet_miccai.txt">[Citation]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/domain.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Domain-Agnostic Learning with Anatomy-Consistent Embedding for Cross-Modality Liver Segmentation
                        </div>
                        <div class='paper-desc'>
			                ICCV 2019, VRMI
                        </div>
                        <div class='paper-authors'>
                            Junlin Yang, Nicha C. Dvornek, <b>Juntang Zhuang</b>, Julius Chapiro, Mingde Lin, James S. Duncan.
                        </div>
                        <div>
                            <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/VRMI/Yang_Domain-Agnostic_Learning_With_Anatomy-Consistent_Embedding_for_Cross-Modality_Liver_Segmentation_ICCVW_2019_paper.pdf">[Paper]</a>
                            <a href="other_citations/domain_adaptation.txt">[Citation]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/laddernet.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            LadderNet: Multi-path networks based on U-Net for medical image segmentation
                        </div>
                        <div class='paper-desc'>
			                arXiv, 2018
                        </div>
                        <div class='paper-authors'>
                           <b>Juntang Zhuang</b>
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/1810.07810">[Paper]</a>
                            <a href="https://github.com/juntang-zhuang/LadderNet">[Code]</a>
                            <a href="other_citations/laddernet.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/sis.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Prediction of treatment outcome for autism from structure of the brain based on sure independence screening
                        </div>
                        <div class='paper-desc'>
			                ISBI 2019
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Nicha C. Dvornek, Qingyu Zhao, Xiaoxiao Li, Pamela Ventola, James S. Duncan.
                        </div>
                        <div>
                            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7119202/pdf/nihms-1568086.pdf">[Paper]</a>
                            <a href="other_citations/sis_pred.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/rf_shadow.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Prediction of Pivotal response treatment outcome with task fMRI using random forest and variable selection
                        </div>
                        <div class='paper-desc'>
			                ISBI 2018
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Nicha C. Dvornek, Xiaoxiao Li, Daniel Yang, Pamela Ventola, James S. Duncan
                        </div>
                        <div>
                            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7532925/">[Paper]</a>
                            <a href="other_citations/shadow.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/two-level-rf.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Prediction of Severity and Treatment Outcome for ASD from fMRI
                        </div>
                        <div class='paper-desc'>
			                MICCAI 2018, PRIME Workshop
                        </div>
                        <div class='paper-authors'>
                            <b>Juntang Zhuang</b>, Nicha C. Dvornek, Xiaoxiao Li, Pamela Ventola, James S. Duncan.
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/1810.11891">[Paper]</a>
                            <a href="other_citations/miccai_2018.txt">[Citation]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/brain-cnn.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Brain biomarker interpretation in ASD using deep learning and fMRI
                        </div>
                        <div class='paper-desc'>
			                MICCAI 2018
                        </div>
                        <div class='paper-authors'>
                            Xiaoxiao Li, Nicha C. Dvornek, <b>Juntang Zhuang</b>, Pamela Ventola, James S. Duncan.
                        </div>
                        <div>
                            <a href="https://arxiv.org/pdf/1808.08296.pdf">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src="imgs/brain-cnn2.png" class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            2-channel convolutional 3D deep neural network (2CC3D) for fMRI analysis: ASD classification and feature learning
                        </div>
                        <div class='paper-desc'>
			                ISBI 2018
                        </div>
                        <div class='paper-authors'>
                            Xiaoxiao Li, Nicha C. Dvornek, <b>Juntang Zhuang</b>, Pamela Ventola, James S. Duncan.
                        </div>
                        <div>
                            <a href="https://ieeexplore.ieee.org/document/8363798">[Paper]</a>
                        </div>
                    </div>
                </div>

                
            </div>
        </div>
    </div>


    <div id='footer' class='vspace-top'>
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
